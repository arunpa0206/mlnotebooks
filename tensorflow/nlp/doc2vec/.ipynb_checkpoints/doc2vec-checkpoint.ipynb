{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "executionInfo": {
     "elapsed": 3702,
     "status": "error",
     "timestamp": 1614453586159,
     "user": {
      "displayName": "meenakshi meyyammai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqOL6XSRGNDaYfV_dgRFMRv7m8ABRr31ql5RGa4g=s64",
      "userId": "11768016833716445346"
     },
     "user_tz": -330
    },
    "id": "LXZ7QEOn7RBO",
    "outputId": "ce56fee8-dc2b-4767-85a7-8c0245ef444b"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Import all the dependencies\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "#Letâ€™s prepare data for training our doc2vec model\n",
    "data = [\"I love machine learning. Its awesome.\",\n",
    "        \"I love coding in python\",\n",
    "        \"I love building chatbots\",\n",
    "        \"they chat amagingly well\"]\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3683,
     "status": "aborted",
     "timestamp": 1614453586154,
     "user": {
      "displayName": "meenakshi meyyammai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqOL6XSRGNDaYfV_dgRFMRv7m8ABRr31ql5RGa4g=s64",
      "userId": "11768016833716445346"
     },
     "user_tz": -330
    },
    "id": "VMTYM4hW7n2H"
   },
   "outputs": [],
   "source": [
    "\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha,\n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1904,
     "status": "ok",
     "timestamp": 1614453830375,
     "user": {
      "displayName": "meenakshi meyyammai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqOL6XSRGNDaYfV_dgRFMRv7m8ABRr31ql5RGa4g=s64",
      "userId": "11768016833716445346"
     },
     "user_tz": -330
    },
    "id": "LCX1Hbjw7peP",
    "outputId": "b7057bab-4940-4eb2-f373-cee153b7d40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "V1_infer [ 0.02283947  0.01276877 -0.01596858 -0.00628765 -0.00446294 -0.01541601\n",
      "  0.01458158 -0.02279644  0.01538679 -0.00372816  0.0135675   0.01388538\n",
      " -0.01890738  0.00278253 -0.02712167 -0.01316682 -0.0022349  -0.01311206\n",
      "  0.00565505  0.00305373]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "#to find the vector of a document which is not in training data\n",
    "test_data = word_tokenize(\"I love chatbots\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 876,
     "status": "ok",
     "timestamp": 1614453838274,
     "user": {
      "displayName": "meenakshi meyyammai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqOL6XSRGNDaYfV_dgRFMRv7m8ABRr31ql5RGa4g=s64",
      "userId": "11768016833716445346"
     },
     "user_tz": -330
    },
    "id": "5WPO6qfD7rpE",
    "outputId": "da672461-4e63-4252-ec5e-dbb3fdbaaf86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', 0.9938875436782837), ('2', 0.9897791743278503), ('3', 0.988804042339325)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# to find most similar doc using tags\n",
    "similar_doc = model.docvecs.most_similar('1')\n",
    "print(similar_doc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGnFaF8x8o4K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQelnQ6Z2j4UPG/JLNCfs2",
   "name": "doc2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
